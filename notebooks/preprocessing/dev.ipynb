{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 216,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 基本ライブラリ\n",
                "import sys\n",
                "from pathlib import Path\n",
                "import pandas as pd\n",
                "\n",
                "# Jupyter環境でのカレントディレクトリを使う\n",
                "current_dir = Path.cwd()  # 現在の作業ディレクトリ\n",
                "sys.path.append(str(current_dir.resolve().parent.parent))\n",
                "SAVE_DIR = Path(\"data\", \"rawdf\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 222,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\kenni\\horse_racing_predictions\n"
                    ]
                }
            ],
            "source": [
                "full_path = Path(sys.path[-1])\n",
                "print(full_path)\n",
                "race_results = pd.read_csv(full_path / SAVE_DIR / \"preprocessed_race_results.csv\", sep=\"\\t\")\n",
                "horse_results = pd.read_csv(full_path / SAVE_DIR / \"preprocessed_horse_results.csv\", sep=\"\\t\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "horse_results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "horse_id_list = [2012100683,2022110151]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "horse_results.query(\"horse_id in @horse_id_list\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# レース情報取得\n",
                "\n",
                "from bs4 import BeautifulSoup\n",
                "import re\n",
                "# 定数の定義\n",
                "HTML_DIR = Path(\"data\", \"html\")\n",
                "SAVE_DIR = Path(\"data\", \"rawdf\")\n",
                "HTML_RACE_DIR = HTML_DIR / \"race\"\n",
                "HTML_HORSE_DIR = HTML_DIR / \"horse\"\n",
                "html_path_list = list((full_path / HTML_RACE_DIR).glob(\"*bin\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(html_path_list[0], \"rb\") as f:\n",
                "    html = f.read()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "html"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "soup = BeautifulSoup(html, \"lxml\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "soup_info = soup.find(\"div\",class_=\"data_intro\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "soup_info"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "soup_info.find(\"h1\").text"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tmp = soup_info.find(\"p\").text.replace(\" \",\"\")\n",
                "tmp"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# バイナリ文字摘出\n",
                "re.findall(r\"\\w+\",tmp)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# :も抽出\n",
                "re.findall(r\"[\\w:]+\",tmp)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tmp_1 = soup.find_all(\"p\")[4].text\n",
                "tmp_1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "re.findall(r\"[\\w:]+\",tmp_1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "info_dict = {}\n",
                "info_dict[\"title\"] = soup_info.find(\"h1\").text\n",
                "info_dict[\"info1\"] = re.findall(\n",
                "    r\"[\\w:]+\", soup_info.find(\"p\").text.replace(\" \",\"\")\n",
                ")\n",
                "info_dict[\"info2\"] = re.findall(\n",
                "    r\"[\\w:]+\", soup.find_all(\"p\")[4].text\n",
                ")\n",
                "info_dict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pd.DataFrame().from_dict(info_dict, orient=\"index\").T"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tqdm import tqdm_notebook as tqdm\n",
                "\n",
                "RACE_INFO_CSV = \"race_info.csv\"\n",
                "dfs = {}\n",
                "# 日付の正規表現パターン\n",
                "DATE_PATTERN = r'\\d{4}年\\d{1,2}月\\d{1,2}日'\n",
                "\n",
                "for html_path in tqdm(html_path_list):\n",
                "    with open(html_path, \"rb\") as f:\n",
                "        try:\n",
                "            html = f.read()\n",
                "            soup = BeautifulSoup(html, \"lxml\").find(\"div\", class_=\"data_intro\")\n",
                "            info_dict = {}\n",
                "            info_dict[\"title\"] = soup.find(\"h1\").text\n",
                "            p_list = soup.find_all(\"p\")\n",
                "            # レース名取得\n",
                "            info_dict[\"info1\"] = re.findall(r\"[\\w:]+\", p_list[0].text.replace(\" \", \"\"))\n",
                "            # 日付を含むpタグ取得\n",
                "            for i, p_2 in enumerate(p_list):\n",
                "                if re.search(DATE_PATTERN, p_2.text):\n",
                "                    break  # 最初に見つかったものだけ欲しいなら break\n",
                "            info_dict[\"info2\"] = re.findall(r\"[\\w:]+\", p_2.text)\n",
                "            df = pd.DataFrame.from_dict(info_dict, orient=\"index\").T\n",
                "            # ファイル名からrace_idを取得\n",
                "            race_id = html_path.stem\n",
                "            df.index = [race_id] * len(df)\n",
                "            dfs[race_id] = df\n",
                "        except IndexError as e:\n",
                "            print(f\"table not found at {race_id}\")\n",
                "            continue\n",
                "        except AttributeError as e:\n",
                "            print(f\"{e} at {race_id}\")\n",
                "            continue\n",
                "\n",
                "concat_df = pd.concat(dfs.values())\n",
                "concat_df.index.name = \"race_id\"\n",
                "concat_df.columns = concat_df.columns.str.replace(\" \", \"\")\n",
                "SAVE_DIR.mkdir(exist_ok=True, parents=True)\n",
                "concat_df.to_csv(SAVE_DIR / RACE_INFO_CSV, sep=\"\\t\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "race_infos = pd.read_csv(full_path / SAVE_DIR / \"race_info.csv\", sep=\"\\t\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "race_infos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# race_id: レースのID\n",
                "# 正規表現マッチング処理の関数化\n",
                "def get_match(pattern, string, group_num=1):\n",
                "    match = re.search(pattern, string)\n",
                "    return match.group(group_num) if match else None\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 正規表現パターン\n",
                "RACE_TYPE_PATTERN = r\"(芝|ダ|障)\"\n",
                "AROUND_PATTERN = r\"(右|左)\"\n",
                "CORCE_LEN_PATTERN = r\"(\\d+)m\"\n",
                "GROUND_STATE_PATTERN = r\"(芝|ダート|障):(.+)\"\n",
                "PLACE_PATTERN = r\"(\\d+回(\\w+)\\d日目)\"\n",
                "\n",
                "# カラム列名\n",
                "COLUMN_RACE_ID = \"race_id\"\n",
                "COLUMN_HORSE_ID = \"horse_id\"\n",
                "COLUMN_JOCKEY_ID = \"jockey_id\"\n",
                "COLUMN_TRAINER_ID = \"trainer_id\"\n",
                "COLUMN_OWNER_ID = \"owner_id\"\n",
                "COLUMN_RANK = \"rank\"\n",
                "COLUMN_WAKUBAN = \"wakuban\"\n",
                "COLUMN_UMABAN = \"umaban\"\n",
                "COLUMN_SEX = \"sex\"\n",
                "COLUMN_AGE = \"age\"\n",
                "COLUMN_WEIGHT = \"weight\"\n",
                "COLUMN_WEIGHT_DIFF = \"weight_diff\"\n",
                "COLUMN_TANSYO = \"tansyo\"\n",
                "COLUMN_POPULARITY = \"popularity\"\n",
                "COLUMN_IMPOST = \"impost\"\n",
                "COLUMN_DATE = \"date\"\n",
                "COLUMN_WEATHER = \"weather\"\n",
                "COLUMN_RACE_TYPE = \"race_type\"\n",
                "COLUMN_COURSE_LEN = \"course_len\"\n",
                "COLUMN_GROUND_STATE = \"ground_state\"\n",
                "COLUMN_RANK_DIFF = \"rank_diff\"\n",
                "COLUMN_PRIZE = \"prize\"\n",
                "COLUMN_RACE_CLASS = \"race_class\"\n",
                "COLUMN_AROUND = \"around\"\n",
                "COLUMN_PLACE = \"place\"\n",
                "\n",
                "import pandas as pd\n",
                "import ast\n",
                "import re\n",
                "\n",
                "# 必要な列名\n",
                "columns = [\n",
                "    COLUMN_RACE_ID,\n",
                "    COLUMN_DATE,\n",
                "    COLUMN_RACE_TYPE,\n",
                "    COLUMN_AROUND,\n",
                "    COLUMN_COURSE_LEN,\n",
                "    COLUMN_WEATHER,\n",
                "    COLUMN_GROUND_STATE,\n",
                "    COLUMN_RACE_CLASS,\n",
                "    COLUMN_PLACE,\n",
                "]\n",
                "\n",
                "# 空のデータフレームを作成（最終結果を格納）\n",
                "result_df = pd.DataFrame(columns=columns)\n",
                "\n",
                "# 各行をループ処理\n",
                "for index, row in race_infos.iterrows():\n",
                "    # info1 と info2 を文字列から辞書またはリストに変換\n",
                "    info1 = ast.literal_eval(row['info1'])\n",
                "    info2 = ast.literal_eval(row['info2'])\n",
                "\n",
                "    # 各列の値を計算\n",
                "    race_id = row[\"race_id\"]\n",
                "    formatted_date = re.sub(r\"(\\d+)年(\\d+)月(\\d+)日\", r\"\\1-\\2-\\3\", info2[0])\n",
                "    formatted_date = re.sub(r\"-(\\d)-\", r\"-0\\1-\", formatted_date) # 月の0埋め\n",
                "    formatted_date = re.sub(r\"-(\\d)$\", r\"-0\\1\", formatted_date)  # 日の0埋め\n",
                "    race_type = get_match(RACE_TYPE_PATTERN, info1[0])\n",
                "    around = get_match(AROUND_PATTERN, info1[0])\n",
                "    course_len = get_match(CORCE_LEN_PATTERN, info1[0])\n",
                "    weather = info1[1][3:]\n",
                "    ground_state = get_match(GROUND_STATE_PATTERN, info1[2], group_num=2)\n",
                "    race_class = info2[2]\n",
                "    place = get_match(PLACE_PATTERN, info2[1], group_num=2)\n",
                "\n",
                "    # 新しい行を作成\n",
                "    new_row = {\n",
                "        COLUMN_RACE_ID: race_id,\n",
                "        COLUMN_DATE: formatted_date,\n",
                "        COLUMN_RACE_TYPE: race_type,\n",
                "        COLUMN_AROUND: around,\n",
                "        COLUMN_COURSE_LEN: course_len,\n",
                "        COLUMN_WEATHER: weather,\n",
                "        COLUMN_GROUND_STATE: ground_state,\n",
                "        COLUMN_RACE_CLASS: race_class,\n",
                "        COLUMN_PLACE: place,\n",
                "    }\n",
                "\n",
                "    # 新しい行を DataFrame に追加\n",
                "    result_df = pd.concat([result_df, pd.DataFrame([new_row])], ignore_index=True)\n",
                "\n",
                "# 保存処理\n",
                "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
                "result_df.to_csv(SAVE_DIR / \"race_info_transformed.csv\", sep=\"\\t\", index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 266,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\kenni\\horse_racing_predictions\\notebooks\\preprocessing\\mapping\n"
                    ]
                },
                {
                    "ename": "AttributeError",
                    "evalue": "'MappingLoader' object has no attribute 'get_around_mapping'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[266], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m df[COLUMN_DATE] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[COLUMN_DATE])\n\u001b[0;32m      9\u001b[0m df[COLUMN_RACE_TYPE] \u001b[38;5;241m=\u001b[39m df[COLUMN_RACE_TYPE]\u001b[38;5;241m.\u001b[39mmap(mapping_loader\u001b[38;5;241m.\u001b[39mget_race_type_mapping())\n\u001b[1;32m---> 10\u001b[0m df[COLUMN_AROUND] \u001b[38;5;241m=\u001b[39m df[COLUMN_AROUND]\u001b[38;5;241m.\u001b[39mmap(\u001b[43mmapping_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_around_mapping\u001b[49m())\n\u001b[0;32m     11\u001b[0m df[COLUMN_COURSE_LEN] \u001b[38;5;241m=\u001b[39m df[COLUMN_COURSE_LEN]\u001b[38;5;241m.\u001b[39mmap(mapping_loader\u001b[38;5;241m.\u001b[39mget_cource_len_mapping())\n\u001b[0;32m     12\u001b[0m df[COLUMN_WEATHER] \u001b[38;5;241m=\u001b[39m df[COLUMN_WEATHER]\u001b[38;5;241m.\u001b[39mmap(mapping_loader\u001b[38;5;241m.\u001b[39mget_weather_mapping())\n",
                        "\u001b[1;31mAttributeError\u001b[0m: 'MappingLoader' object has no attribute 'get_around_mapping'"
                    ]
                }
            ],
            "source": [
                "# mappingファイル読み込み\n",
                "from mapping import MappingLoader\n",
                "current_dir = Path.cwd()  # 現在の作業ディレクトリ\n",
                "print(current_dir / \"mapping\")\n",
                "mapping_loader = MappingLoader(mapping_dir = current_dir / \"mappng\")\n",
                "\n",
                "df = pd.read_csv(SAVE_DIR / \"race_info_transformed.csv\", sep=\"\\t\")\n",
                "df[COLUMN_DATE] = pd.to_datetime(df[COLUMN_DATE])\n",
                "df[COLUMN_RACE_TYPE] = df[COLUMN_RACE_TYPE].map(mapping_loader.get_race_type_mapping())\n",
                "df[COLUMN_AROUND] = df[COLUMN_AROUND].map(mapping_loader.get_around_mapping())\n",
                "df[COLUMN_COURSE_LEN] = df[COLUMN_COURSE_LEN].map(mapping_loader.get_cource_len_mapping())\n",
                "df[COLUMN_WEATHER] = df[COLUMN_WEATHER].map(mapping_loader.get_weather_mapping())\n",
                "df[COLUMN_GROUND_STATE] = df[COLUMN_GROUND_STATE].map(mapping_loader.get_ground_state_mapping())\n",
                "df[COLUMN_RACE_CLASS] = df[COLUMN_RACE_CLASS].map(mapping_loader.get_race_class_info_mapping())\n",
                "df[COLUMN_PLACE] = df[COLUMN_PLACE].map(mapping_loader.get_place_mapping())\n",
                "# ここに使用する列名を列挙\n",
                "df = df[\n",
                "    [\n",
                "        COLUMN_RACE_ID,\n",
                "        COLUMN_DATE,\n",
                "        COLUMN_RACE_TYPE,\n",
                "        COLUMN_AROUND,\n",
                "        COLUMN_COURSE_LEN,\n",
                "        COLUMN_WEATHER,\n",
                "        COLUMN_GROUND_STATE,\n",
                "        COLUMN_RACE_CLASS,\n",
                "        COLUMN_PLACE\n",
                "    ]\n",
                "]\n",
                "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
                "df.to_csv(SAVE_DIR / \"race_info_transformed2.csv\", sep=\"\\t\", index=False)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
